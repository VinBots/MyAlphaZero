{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero Algorithm - Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was built to conduct experiences on the AlphaZero Algorithm and better understand its implementation details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries / modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import games_mod # Games\n",
    "import policy_mod # neural network\n",
    "from play_mod import Play #functionalities of game\n",
    "import training_mod #neural network training\n",
    "from replay_buffer_dict import ReplayBuffer #centralized buffer\n",
    "from utils import DotDict #other utilities\n",
    "from log_data import LogData #logging class for monitoring purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game, Training, Competition, Benchmark and Play Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game settings\n",
    "game_settings = DotDict({\n",
    "    \"board_size\": (3,3),\n",
    "    \"N\": 3\n",
    "})\n",
    "\n",
    "# Self-play training settings\n",
    "game_training_settings = DotDict({\n",
    "    \"generations\": 100,\n",
    "    \"self_play_iterations\": 50,\n",
    "    \"data_augmentation_times\": 1\n",
    "})\n",
    "# alpha = 10 / average legal moves \n",
    "# https://medium.com/oracledevs/lessons-from-alphazero-part-3-parameter-tweaking-4dceb78ed1e5 \n",
    "\n",
    "# Self-play training settings\n",
    "mcts_settings = DotDict({\n",
    "    \"explore_steps\": 50,\n",
    "    \"temp\": 1.0,\n",
    "    \"dir_enabled\": True,\n",
    "    \"dir_eps\": 0.25,\n",
    "    \"dir_alpha\": 2.0,\n",
    "})\n",
    "\n",
    "# neural network settings\n",
    "nn_training_settings = DotDict({\n",
    "    \"load_policy\": False,\n",
    "    \"policy_path\": \"ai_ckp.pth\",\n",
    "    \"ckp_folder\":\"ckp\",\n",
    "    \"lr\": .005, \n",
    "    \"weight_decay\": 1.e-4,\n",
    "    \"buffer_size_target\": 1000,\n",
    "    \"n_epochs\": 1,\n",
    "    \"batch_size\": 50\n",
    "})\n",
    "\n",
    "benchmark_competition_settings = DotDict({\n",
    "    \"compet_freq\":5,\n",
    "    \"compet_rounds\": 2,\n",
    "    \"net_compet_threshold\": 0.0,\n",
    "    \"benchmark_freq\": 5,\n",
    "    \"benchmark_rounds\": 50,\n",
    "    \"mcts_iterations\": 1000,\n",
    "    \"mcts_random_moves\":0\n",
    "})\n",
    "\n",
    "# play settings\n",
    "play_settings = DotDict({\n",
    "    \"explore_steps\": 50,\n",
    "    \"temperature\": 0.01                         \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = LogData()\n",
    "log_data.add_chart(\"nn_loss\", [\"nn_loss.csv\", ['iter', 'loss', 'value_loss', 'prob_loss']])\n",
    "log_data.add_chart(\"buffer\", [\"buffer.csv\", ['iter', 'wins', 'losses', 'draws']])\n",
    "log_data.add_chart(\"compet\", [\"compet.csv\",['iter', 'scores']])\n",
    "\n",
    "game=games_mod.ConnectN(game_settings)\n",
    "\n",
    "policy = policy_mod.Policy(nn_training_settings.policy_path, \n",
    "                           nn_training_settings, \n",
    "                           log_data)\n",
    "policy.save_weights()\n",
    "\n",
    "buffer = ReplayBuffer(nn_training_settings.buffer_size_target, \n",
    "                      nn_training_settings.batch_size, \n",
    "                      log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Generations:   9%|▉         | 9/100 [02:07<18:19, 12.09s/it]Network replaced at generation 9\n",
      "Generations:  14%|█▍        | 14/100 [03:38<17:39, 12.32s/it]Network replaced at generation 14\n",
      "Generations:  19%|█▉        | 19/100 [05:10<16:35, 12.29s/it]Network replaced at generation 19\n",
      "Generations:  39%|███▉      | 39/100 [11:15<12:24, 12.21s/it]Network replaced at generation 39\n",
      "Generations:  49%|████▉     | 49/100 [14:23<10:48, 12.71s/it]Network replaced at generation 49\n",
      "Generations:  54%|█████▍    | 54/100 [15:56<09:32, 12.45s/it]Network replaced at generation 54\n",
      "Generations:  59%|█████▉    | 59/100 [17:30<08:33, 12.53s/it]Network replaced at generation 59\n",
      "Generations:  64%|██████▍   | 64/100 [19:04<07:35, 12.64s/it]Network replaced at generation 64\n",
      "Generations:  74%|███████▍  | 74/100 [22:11<05:22, 12.42s/it]Network replaced at generation 74\n",
      "Generations:  79%|███████▉  | 79/100 [23:45<04:23, 12.56s/it]Network replaced at generation 79\n",
      "Generations:  84%|████████▍ | 84/100 [25:20<03:21, 12.62s/it]Network replaced at generation 84\n",
      "Generations:  89%|████████▉ | 89/100 [26:52<02:16, 12.40s/it]Network replaced at generation 89\n",
      "Generations:  94%|█████████▍| 94/100 [28:24<01:13, 12.24s/it]Network replaced at generation 94\n",
      "Generations:  99%|█████████▉| 99/100 [29:54<00:11, 11.88s/it]Network replaced at generation 99\n",
      "Generations: 100%|██████████| 100/100 [30:55<00:00, 18.55s/it]1855.1561379432678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "alpha_0 = training_mod.AlphaZeroTraining(\n",
    "    game_settings, \n",
    "    game_training_settings,\n",
    "    mcts_settings,\n",
    "    nn_training_settings,\n",
    "    benchmark_competition_settings,\n",
    "    play_settings,\n",
    "    policy,\n",
    "    log_data)\n",
    "alpha_0.training_pipeline(buffer)\n",
    "t1 = time.time()\n",
    "print (t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing some positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import policy_mod  # neural network\n",
    "\n",
    "def test_final_positions(game_state):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    frame = torch.tensor(game_state, dtype=torch.float, device=device).unsqueeze(0).unsqueeze(0)\n",
    "    policy_path = \"ai_ckp.pth\"\n",
    "    policy = policy_mod.Policy(policy_path, nn_training_settings)\n",
    "    policy.load_weights(policy_path)\n",
    "    print (frame)\n",
    "    v, p = policy.forward_batch(frame)\n",
    "    print(\"Probabilities = {}; Values = {}\".format(p, v))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[[-1.,  1., -1.],\n          [ 0.,  1.,  0.],\n          [ 0.,  0.,  0.]]]])\nProbabilities = tensor([[ 8.4970e-08,  8.4970e-08,  8.4970e-08,  1.2820e-03,  8.4970e-08,\n          1.3472e-03,  7.9750e-04,  9.9490e-01,  1.6758e-03]]); Values = tensor([[ 0.8834]])\n"
     ]
    }
   ],
   "source": [
    "game_state1 = np.array([[-1, 1, -1], [0, 1, 0], [0, 0, 0]])\n",
    "test_final_positions (game_state1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[[-1.,  1., -1.],\n          [ 0.,  1., -1.],\n          [ 0.,  0.,  0.]]]])\nProbabilities = tensor([[ 1.0181e-07,  1.0181e-07,  1.0181e-07,  1.5234e-04,  1.0181e-07,\n          1.0181e-07,  2.5640e-04,  9.9826e-01,  1.3306e-03]]); Values = tensor([[ 0.9417]])\n"
     ]
    }
   ],
   "source": [
    "game_state2 = np.array([[-1, 1, -1], [0, 1, -1], [0, 0, 0]])\n",
    "test_final_positions (game_state2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game with 2nd position not in the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[[ 0.,  0.,  0.],\n          [ 0.,  0.,  0.],\n          [ 0.,  0.,  0.]]]])\nProbabilities = tensor([[ 0.1265,  0.0394,  0.1808,  0.0311,  0.3087,  0.0458,  0.0772,\n          0.0497,  0.1408]]); Values = tensor([[-0.1421]])\n"
     ]
    }
   ],
   "source": [
    "game_state3 = np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
    "test_final_positions (game_state3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[[-1.,  0.,  0.],\n          [ 0.,  0.,  0.],\n          [ 0.,  0.,  0.]]]])\nProbabilities = tensor([[ 0.0011,  0.0643,  0.0552,  0.0646,  0.5669,  0.0362,  0.0459,\n          0.0493,  0.1165]]); Values = tensor([[-0.6335]])\n"
     ]
    }
   ],
   "source": [
    "game_state4 = np.array([[-1, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
    "test_final_positions (game_state4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[[ 1.,  0.,  0.],\n          [ 0.,  0., -1.],\n          [ 0.,  0.,  0.]]]])\nProbabilities = tensor([[ 0.0004,  0.1166,  0.4792,  0.0829,  0.1865,  0.0004,  0.1082,\n          0.0050,  0.0208]]); Values = tensor([[ 0.9842]])\n"
     ]
    }
   ],
   "source": [
    "game_state5 = np.array([[1, 0, 0], [0, 0, -1], [0, 0, 0]])\n",
    "test_final_positions (game_state5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[[-1.,  0., -1.],\n          [ 0.,  0.,  1.],\n          [ 0.,  0.,  0.]]]])\nProbabilities = tensor([[ 0.0002,  0.4954,  0.0002,  0.1477,  0.1413,  0.0002,  0.0997,\n          0.0775,  0.0378]]); Values = tensor([[-0.9286]])\n"
     ]
    }
   ],
   "source": [
    "game_state6 = np.array([[-1, 0, -1], [0, 0, 1], [0, 0, 0]])\n",
    "test_final_positions (game_state6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[[ 1., -1.,  1.],\n          [ 0.,  0., -1.],\n          [ 0.,  0.,  0.]]]])\nProbabilities = tensor([[ 0.0000,  0.0000,  0.0000,  0.0092,  0.6929,  0.0000,  0.2636,\n          0.0016,  0.0327]]); Values = tensor([[ 0.9997]])\n"
     ]
    }
   ],
   "source": [
    "game_state7 = np.array([[1, -1, 1], [0, 0, -1], [0, 0, 0]])\n",
    "test_final_positions (game_state7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[[-1.,  1., -1.],\n          [ 0., -1.,  1.],\n          [ 0.,  0.,  0.]]]])\nProbabilities = tensor([[ 0.0001,  0.0001,  0.0001,  0.3398,  0.0001,  0.0001,  0.5126,\n          0.1091,  0.0381]]); Values = tensor([[-0.8974]])\n"
     ]
    }
   ],
   "source": [
    "game_state8 = np.array([[-1, 1, -1], [0, -1, 1], [0, 0, 0]])\n",
    "test_final_positions (game_state8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}