{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero Algorithm - Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was built to conduct experiences on the AlphaZero Algorithm and better understand its implementation details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries / modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import time\n",
    "import random\n",
    "from copy import copy\n",
    "# z3rd party libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Game-related libraries\n",
    "import games_mod # Games\n",
    "import policy_mod # neural network\n",
    "from play_mod import Play\n",
    "import training_mod\n",
    "from game_utils import DotDict, policy_player_mcts, random_player, match_ai, network_only\n",
    "from log_data import LogData\n",
    "import plain_mcts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game, Training and Play Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game settings\n",
    "game_settings = DotDict({\n",
    "    \"board_size\": (3,3),\n",
    "    \"N\": 3\n",
    "})\n",
    "\n",
    "# Self-play training settings\n",
    "game_training_settings = DotDict({\n",
    "    \"comp_interval\":1000,\n",
    "    \"episods\": 300,\n",
    "    \"self_play_iterations\": 50,\n",
    "    \"explore_steps\": 500,\n",
    "    \"temp_threshold\": [30, 0.01],\n",
    "    \"dir_eps\": 0.25,\n",
    "    \"dir_alpha\": 1.0 \n",
    "})\n",
    "\n",
    "# temp_threshold: [x,y] means \"up to x episods, applies y temperature\"\n",
    "\n",
    "# neural network settings\n",
    "nn_training_settings = DotDict({\n",
    "    \"load_policy\": False,\n",
    "    \"ai_ckp\": \"\",\n",
    "    \"lr\": .01, \n",
    "    \"weight_decay\": 1.e-4,\n",
    "    \"training_steps\":30,\n",
    "    \"buffer_size\":1500,\n",
    "    \"batch_size\": 20\n",
    "})\n",
    "\n",
    "# play settings\n",
    "play_settings = DotDict({\n",
    "    \"explore_steps\": 50,\n",
    "    \"temperature\": 0.01                         \n",
    "})\n",
    "\n",
    "buffer_size = nn_training_settings.buffer_size\n",
    "batch_size = nn_training_settings.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from competition import match_net_mcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = policy_mod.Policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0\n",
      "7 1\n",
      "9 0\n",
      "9 0\n",
      "5 1\n",
      "7 1\n",
      "9 0\n",
      "9 0\n",
      "7 1\n",
      "7 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_net_mcts(policy, game_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing MCTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_out (game, nb_roll_out = 5):\n",
    "    scores = []\n",
    "    for _ in range(nb_roll_out):\n",
    "        sim_game = copy(game)\n",
    "        while sim_game.score == None:          \n",
    "            random_move = random.choice(sim_game.available_moves())\n",
    "            #print (random_move)\n",
    "            sim_game.move(random_move)\n",
    "            #print (game.state)\n",
    "        scores.append(sim_game.score)\n",
    "    return np.average(np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_game = games_mod.ConnectN(game_settings)\n",
    "mytree = plain_mcts.Node(new_game)\n",
    "#new_game.state = np.array([[0,1,1],[0,-1, -1],[0,0,0]])\n",
    "#new_game.n_moves = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[ 0.  0. -1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 0.  1. -1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 0.  1. -1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0. -1.  0.]]\n",
      "[[ 0.  1. -1.]\n",
      " [ 0.  1.  1.]\n",
      " [ 0. -1.  0.]]\n",
      "[[ 0.  1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [ 0. -1.  0.]]\n",
      "[[ 1.  1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [ 0. -1.  0.]]\n",
      "[[ 1.  1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [ 0. -1. -1.]]\n",
      "[[ 1.  1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [ 1. -1. -1.]]\n",
      "Game outcome 0\n"
     ]
    }
   ],
   "source": [
    "while mytree.outcome is None:\n",
    "    \n",
    "    for _ in range (1000):\n",
    "        mytree.explore()\n",
    "\n",
    "    mytree = mytree.next(temperature=0.01)\n",
    "    print (mytree.game.state)\n",
    "    #memory.append()\n",
    "    # print (\"Sent to memory {}\".format([state * current_player, p]))\n",
    "    mytree.detach_mother()\n",
    "    outcome = mytree.outcome\n",
    "print (\"Game outcome {}\".format(outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e0efd73f35a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmytree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmytree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmytree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmytree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmytree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 0)"
     ]
    }
   ],
   "source": [
    "print (mytree.child[(0,0)].N)\n",
    "print (mytree.child[(0,1)].N)\n",
    "print (mytree.child[(0,2)].N)\n",
    "print (mytree.child[(1,0)].N)\n",
    "print (mytree.child[(1,1)].N)\n",
    "print (mytree.child[(1,2)].N)\n",
    "print (mytree.child[(2,0)].N)\n",
    "print (mytree.child[(2,1)].N)\n",
    "print (mytree.child[(2,2)].N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent1 = receives last game move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_game = games_mod.ConnectN(game_settings)\n",
    "agent1 = plain_mcts.Node(new_game)\n",
    "agent2 = plain_mcts.Node(new_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_agent(agent, iterations):\n",
    "    for _ in range (iterations):\n",
    "        agent.explore()\n",
    "    agent = agent.next(temperature=0.01)\n",
    "    return agent.game.last_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = 0\n",
    "for _ in range(100):\n",
    "    new_game = games_mod.ConnectN(game_settings)\n",
    "    agent1 = plain_mcts.Node(new_game)\n",
    "    agent2 = plain_mcts.Node(new_game)\n",
    "    turn = 0\n",
    "    seq_states = []\n",
    "\n",
    "    while new_game.score is None and turn < 2:\n",
    "        #print (new_game.state)\n",
    "        if turn % 2 == 0 and turn > 1:\n",
    "            agent1 = plain_mcts.Node(new_game)\n",
    "            new_game.move (play_agent(agent1, 500))\n",
    "        elif turn % 2 == 0:\n",
    "            #new_game.move (random.choice(new_game.available_moves()))\n",
    "            new_game.move ((2,1))\n",
    "        else:\n",
    "            agent2 = plain_mcts.Node(new_game)\n",
    "            new_game.move (play_agent(agent2, 2000))\n",
    "        seq_states.append(copy(new_game.state))\n",
    "        turn +=1\n",
    "    if new_game.score == 1:\n",
    "        stored_game = new_game\n",
    "        stored_seq_states = seq_states\n",
    "        break\n",
    "    #scores += new_game.score\n",
    "    #print (turn, new_game.score)\n",
    "    del new_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
