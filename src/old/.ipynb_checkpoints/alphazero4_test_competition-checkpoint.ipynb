{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero Algorithm - Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was built to conduct experiences on the AlphaZero Algorithm and better understand its implementation details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries / modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import time\n",
    "\n",
    "# z3rd party libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Game-related libraries\n",
    "import games_mod # Games\n",
    "import policy_mod # neural network\n",
    "from play_mod import Play\n",
    "import training_mod\n",
    "from game_utils import DotDict, policy_player_mcts, random_player, match_ai, network_only\n",
    "from log_data import LogData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game, Training and Play Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game settings\n",
    "game_settings = DotDict({\n",
    "    \"board_size\": (3,3),\n",
    "    \"N\": 3\n",
    "})\n",
    "\n",
    "# Self-play training settings\n",
    "game_training_settings = DotDict({\n",
    "    \"comp_interval\":1000,\n",
    "    \"episods\": 300,\n",
    "    \"self_play_iterations\": 50,\n",
    "    \"explore_steps\": 2,\n",
    "    \"temp_threshold\": [50, 0.01],\n",
    "    \"dir_eps\": 0.25,\n",
    "    \"dir_alpha\": 1.0 \n",
    "})\n",
    "\n",
    "# temp_threshold: [x,y] means \"up to x episods, applies y temperature\"\n",
    "\n",
    "# neural network settings\n",
    "nn_training_settings = DotDict({\n",
    "    \"load_policy\": False,\n",
    "    \"ai_ckp\": \"\",\n",
    "    \"lr\": .01, \n",
    "    \"weight_decay\": 1.e-4,\n",
    "    \"training_steps\":30,\n",
    "    \"buffer_size\":1500,\n",
    "    \"batch_size\": 20\n",
    "})\n",
    "\n",
    "# play settings\n",
    "play_settings = DotDict({\n",
    "    \"explore_steps\": 50,\n",
    "    \"temperature\": 0.01                         \n",
    "})\n",
    "\n",
    "buffer_size = nn_training_settings.buffer_size\n",
    "batch_size = nn_training_settings.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Play Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total wins / losses of Player 1 : 0 / 100\n"
     ]
    }
   ],
   "source": [
    "total_wins, total_losses = match_ai(game_settings, play_settings, network_only, network_only, total_rounds = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
