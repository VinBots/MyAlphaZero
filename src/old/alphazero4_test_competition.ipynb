{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero Algorithm - Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was built to conduct experiences on the AlphaZero Algorithm and better understand its implementation details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries / modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import time\n",
    "\n",
    "# z3rd party libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Game-related libraries\n",
    "import games_mod # Games\n",
    "import policy_mod # neural network\n",
    "from play_mod import Play\n",
    "import training_mod\n",
    "from game_utils import DotDict, policy_player_mcts, random_player, match_ai, network_only\n",
    "from log_data import LogData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game, Training and Play Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game settings\n",
    "game_settings = DotDict({\n",
    "    \"board_size\": (3,3),\n",
    "    \"N\": 3\n",
    "})\n",
    "\n",
    "# Self-play training settings\n",
    "game_training_settings = DotDict({\n",
    "    \"comp_interval\":1000,\n",
    "    \"episods\": 100,\n",
    "    \"self_play_iterations\": 50,\n",
    "    \"explore_steps\": 500,\n",
    "    \"temp_threshold\": [50, 0.01],\n",
    "    \"dir_eps\": 0.25,\n",
    "    \"dir_alpha\": 1.0 \n",
    "})\n",
    "\n",
    "# temp_threshold: [x,y] means \"up to x episods, applies y temperature\"\n",
    "\n",
    "# neural network settings\n",
    "nn_training_settings = DotDict({\n",
    "    \"load_policy\": False,\n",
    "    \"ai_ckp\": \"\",\n",
    "    \"lr\": .01, \n",
    "    \"weight_decay\": 1.e-4,\n",
    "    \"training_steps\":30,\n",
    "    \"buffer_size\":1500,\n",
    "    \"batch_size\": 20\n",
    "})\n",
    "\n",
    "# play settings\n",
    "play_settings = DotDict({\n",
    "    \"explore_steps\": 50,\n",
    "    \"temperature\": 0.01                         \n",
    "})\n",
    "\n",
    "buffer_size = nn_training_settings.buffer_size\n",
    "batch_size = nn_training_settings.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Play Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "tensor([[[[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]]]]) [[0.13761409 0.0903748  0.15134129]\n",
      " [0.08667693 0.11487675 0.08641278]\n",
      " [0.14266936 0.07666049 0.11337356]]\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "tensor([[[[-0., -0., -1.],\n",
      "          [-0., -0., -0.],\n",
      "          [-0., -0., -0.]]]]) [[0.08661634 0.1030232  0.        ]\n",
      " [0.08133116 0.22488971 0.10132253]\n",
      " [0.20639579 0.08938055 0.10673177]]\n",
      "[[ 0.  0.  1.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "tensor([[[[ 0.,  0.,  1.],\n",
      "          [ 0., -1.,  0.],\n",
      "          [ 0.,  0.,  0.]]]]) [[0.19766623 0.10648648 0.        ]\n",
      " [0.11144192 0.         0.15153173]\n",
      " [0.11327257 0.09444978 0.22206922]]\n",
      "[[ 0.  0.  1.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "tensor([[[[-0., -0., -1.],\n",
      "          [-0.,  1., -0.],\n",
      "          [-0., -0., -1.]]]]) [[0.08774607 0.14426005 0.        ]\n",
      " [0.09272014 0.         0.50685096]\n",
      " [0.05548812 0.11263628 0.        ]]\n",
      "[[ 0.  0.  1.]\n",
      " [ 0. -1. -1.]\n",
      " [ 0.  0.  1.]]\n",
      "tensor([[[[ 0.,  0.,  1.],\n",
      "          [ 0., -1., -1.],\n",
      "          [ 0.,  0.,  1.]]]]) [[0.08126384 0.09532175 0.        ]\n",
      " [0.74253154 0.         0.        ]\n",
      " [0.01720737 0.06198367 0.        ]]\n",
      "[[ 0.  0.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 0.  0.  1.]]\n",
      "tensor([[[[-0., -0., -1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [-0., -0., -1.]]]]) [[0.2897008  0.45774004 0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.07343955 0.17730017 0.        ]]\n",
      "[[ 0. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 0.  0.  1.]]\n",
      "tensor([[[[ 0., -1.,  1.],\n",
      "          [ 1., -1., -1.],\n",
      "          [ 0.,  0.,  1.]]]]) [[0.2773136  0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.14523597 0.5737417  0.        ]]\n",
      "[[ 0. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 0.  1.  1.]]\n",
      "tensor([[[[-0.,  1., -1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [-0., -1., -1.]]]]) [[0.5909832  0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.40057504 0.         0.        ]]\n",
      "[[-1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [ 0.  1.  1.]]\n",
      "tensor([[[[-1., -1.,  1.],\n",
      "          [ 1., -1., -1.],\n",
      "          [ 0.,  1.,  1.]]]]) [[0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.99538344 0.         0.        ]]\n",
      "Total wins / losses of Player 1 : 1 / 0\n"
     ]
    }
   ],
   "source": [
    "total_wins, total_losses = match_ai(game_settings, play_settings, network_only, network_only, total_rounds = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities = [[1.23858033e-03 1.09221607e-01 3.44767809e-01 1.17241390e-01\n",
      "  1.60804167e-01 1.22051708e-01 1.23858033e-03 1.23858033e-03\n",
      "  1.42197609e-01]\n",
      " [1.73365478e-07 1.00252895e-04 2.01736786e-03 2.14605927e-04\n",
      "  2.68485583e-03 9.72873648e-04 1.73365478e-07 1.73365478e-07\n",
      "  9.94009495e-01]], [[1.23858033e-03 1.09221607e-01 3.44767809e-01 1.17241390e-01\n",
      "  1.60804167e-01 1.22051708e-01 1.23858033e-03 1.23858033e-03\n",
      "  1.42197609e-01]\n",
      " [1.73365478e-07 1.00252895e-04 2.01736786e-03 2.14605927e-04\n",
      "  2.68485583e-03 9.72873648e-04 1.73365478e-07 1.73365478e-07\n",
      "  9.94009495e-01]]; Values = [[0.07414395]\n",
      " [0.99949706]], [[0.07414395]\n",
      " [0.99949706]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "game_state1 = np.array([[1, 0, 0], [0, 0, 0], [-1, -1, 0]])\n",
    "\n",
    "game_state2 = np.array([[-1, 0, 0], [0, 0, 0], [1, 1, 0]])\n",
    "\n",
    "\n",
    "frame1 = torch.tensor(game_state1, dtype=torch.float, device=device).unsqueeze(0)\n",
    "frame2 = torch.tensor(game_state2, dtype=torch.float, device=device).unsqueeze(0)\n",
    "\n",
    "policy_path = \"ai_ckp.pth\"\n",
    "policy = policy_mod.Policy()\n",
    "policy.load_weights(policy_path)\n",
    "\n",
    "new_tensor = torch.stack((frame1, frame2))\n",
    "v, p = policy.forward_batch(new_tensor)\n",
    "v1 = v.detach().numpy()\n",
    "v2 = v.detach().numpy()\n",
    "\n",
    "p1 = p.detach().numpy()\n",
    "p2 = p.detach().numpy()\n",
    "\n",
    "print(\"Probabilities = {}, {}; Values = {}, {}\".format(p1, p2, v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
